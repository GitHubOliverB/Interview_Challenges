{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Of Addresses\n",
    "\n",
    "You are given a dataset of special locations (e.g. restaurants). The dataset features the name of the location, a special property (e.g. cuisine) and the address, which is broken down into street, street number, post code, city and country.\n",
    "\n",
    "Furthermore you are given an other dataset of more locations. Your task is to add new locations from the second dataset to the first dataset, while avoiding the creation of duplicates. Keep in mind that one location may have multiple addresses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Python Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Distance Measurements\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm assuming that the list provides valid locations, without any typos or missing information. The only possible problem to occur is if a location has multiple addresses. This can be the case if the location is right at an intersection. Otherwise we could simply compare all features for a possible new location with the features of the locations in the first dataset.\n",
    "\n",
    "A fast, yet unrealiable methode would be to simply compare the post code of locations with the same name. This may work really good, but it certainly has the potential to erroneously identify a location as a duplicate. A possible example of that are multiple Lidl's with the same post code.\n",
    "\n",
    "In order for us to avoid that error, we would need to make use of the street names. It would be really neat if we had a way to check if there is an alternative address for any given address. That would trivialise the problem.\n",
    "\n",
    "Since I don't have that kind of information at hand, I'm going with a more practical approach. If a possible new location from the list shares all features but the street and street number with at least of the locations inside our dataset, I'll calculate the distance between the pairs of addresses using [geopy](https://pypi.org/project/geopy/). If the distance is less than a certain threshold, the location is assumed to be a duplicate.\n",
    "\n",
    "To solve the problem, I need one function to compute the distance of two locations and one function to merge both dataset, identify duplicates and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_addresses(str_address_1, str_address_2):\n",
    "    \"\"\"\n",
    "    Takes two address strings as an input.\n",
    "    The output is the distance between the two addresses in meters.\n",
    "    \"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"Oliver.Bey91@gmail.com\")\n",
    "    location_1 = geolocator.geocode(str_address_1)\n",
    "    location_2 = geolocator.geocode(str_address_2)\n",
    "    return geodesic((location_1.latitude, location_1.longitude), (location_2.latitude, location_2.longitude)).m\n",
    "\n",
    "def datapoint_compare(feature_list, known_location_df, new_location_df, distance_threshold):\n",
    "    \"\"\"\n",
    "    Takes four inputs. The first input is a list of features which shall be compared between two datapoints.\n",
    "    The second input will be the dataset containing known locations. \n",
    "    As a third input, the function takes an other dataset with possible new locations.\n",
    "    As the last input, we need to specify the threshold for the distance in meters.\n",
    "    The output will be a modified version of the dataset containing all unique locations.\n",
    "    \"\"\"\n",
    "    output_df = pd.concat([known_location_df, new_location_df]).reset_index()\n",
    "    output_df = output_df.drop_duplicates() \n",
    "    output_df['address_string'] = output_df['street'] + \\\n",
    "                                  \" \" + output_df['street_number'] + \\\n",
    "                                  \", \" + output_df['post_code'] + \\\n",
    "                                  \" \" + output_df['city'] + \\\n",
    "                                  \", \" + output_df['country']\n",
    "    unique_name_list = list(output_df['name'].unique())\n",
    "    for name in unique_name_list:\n",
    "        unique_post_code_list = list(output_df['post_code'][output_df['name'] == name].unique())\n",
    "        for post_code in unique_post_code_list:\n",
    "            unique_country_list = list(output_df['country'][(output_df['name'] == name) & \n",
    "                                                           (output_df['post_code'] == post_code)].unique())\n",
    "            for country in unique_country_list:\n",
    "                df = output_df[(output_df['name'] == name) &\n",
    "                               (output_df['post_code'] == post_code) &\n",
    "                               (output_df['country'] == country)].reset_index()\n",
    "                if len(df) > 1:\n",
    "                    address_combinations = list(itertools.combinations(df['address_string'].values, 2))\n",
    "                    for combinations in address_combinations:\n",
    "                        if distance_addresses(combinations[0], combinations[1]) < distance_threshold:\n",
    "                            print(\"Duplicate detected!\")\n",
    "                            print(name + \", \" + combinations[1])\n",
    "                            output_df = output_df.loc[~((output_df['name'] == name) &\n",
    "                                                  (output_df['post_code'] == post_code) &\n",
    "                                                  (output_df['country'] == country) &\n",
    "                                                  (output_df['address_string'] == combinations[1])),:]\n",
    "    print(\"\\nRemoving duplicates via address distance completed.\")\n",
    "    print(\"Final dataframe:\\n\")\n",
    "    print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        name   cuisine           street  \\\n",
      "0  Gaffel Haus Berlin - Das Kölsche Konsulat    German  Dorotheenstraße   \n",
      "1                     Galeria Kaufhof Berlin  European   Alexanderplatz   \n",
      "0                            Sapori Italiani   Italian   Alexanderplatz   \n",
      "1                     Galeria Kaufhof Berlin  European     Dircksenstr.   \n",
      "\n",
      "  street_number post_code    city  country  \n",
      "0            65     10117  Berlin  Germany  \n",
      "1             9     10178  Berlin  Germany  \n",
      "0             9     10178  Berlin  Germany  \n",
      "1             2     10178  Berlin  Germany  \n"
     ]
    }
   ],
   "source": [
    "feature_list = ['name', 'cuisine', 'street', 'street_number', 'post_code', 'city', 'country']\n",
    "\n",
    "data_1 = {'name': ['Gaffel Haus Berlin - Das Kölsche Konsulat', 'Galeria Kaufhof Berlin'],\n",
    "          'cuisine': ['German', 'European', ],\n",
    "          'street': ['Dorotheenstraße', 'Alexanderplatz'],\n",
    "          'street_number': ['65', '9'],\n",
    "          'post_code': ['10117', '10178'],\n",
    "          'city': ['Berlin', 'Berlin'],\n",
    "          'country': ['Germany', 'Germany']\n",
    "           }\n",
    "\n",
    "data_2 = {'name': ['Sapori Italiani', 'Galeria Kaufhof Berlin'],\n",
    "          'cuisine': ['Italian', 'European', ],\n",
    "          'street': ['Alexanderplatz', 'Dircksenstr.'],\n",
    "          'street_number': ['9', '2'],\n",
    "          'post_code': ['10178', '10178'],\n",
    "          'city': ['Berlin', 'Berlin'],\n",
    "          'country': ['Germany', 'Germany']\n",
    "           }\n",
    "\n",
    "df_1 = pd.DataFrame(data_1, columns = feature_list)\n",
    "df_2 = pd.DataFrame(data_2, columns = feature_list)\n",
    "\n",
    "print(pd.concat([df_1, df_2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would simply merge our dataframes, we would end up with the above presentation. Now as you can see, there are two entries for __Galeria Kaufhof Berlin__. To create a duplicate, I simply picked a close by address for the second entry. Now I hope to remove that entry from our final list.\n",
    "\n",
    "And since I'm also worried that the first dataframe may already contain duplicates, I will compute the distance for all possible combinations of entries with the same name, post code and country. If a pair of addresses is found with a distance smaller than the threshold, it will be removed from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate detected!\n",
      "Galeria Kaufhof Berlin, Dircksenstr. 2, 10178 Berlin, Germany\n",
      "\n",
      "Removing duplicates via address distance completed.\n",
      "Final dataframe:\n",
      "\n",
      "   index                                       name   cuisine  \\\n",
      "0      0  Gaffel Haus Berlin - Das Kölsche Konsulat    German   \n",
      "1      1                     Galeria Kaufhof Berlin  European   \n",
      "2      0                            Sapori Italiani   Italian   \n",
      "\n",
      "            street street_number post_code    city  country  \\\n",
      "0  Dorotheenstraße            65     10117  Berlin  Germany   \n",
      "1   Alexanderplatz             9     10178  Berlin  Germany   \n",
      "2   Alexanderplatz             9     10178  Berlin  Germany   \n",
      "\n",
      "                              address_string  \n",
      "0  Dorotheenstraße 65, 10117 Berlin, Germany  \n",
      "1    Alexanderplatz 9, 10178 Berlin, Germany  \n",
      "2    Alexanderplatz 9, 10178 Berlin, Germany  \n"
     ]
    }
   ],
   "source": [
    "datapoint_compare(feature_list, df_1, df_2, distance_threshold=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the entries\n",
    "\n",
    "* Galeria Kaufhof Berlin, Alexanderplatz 9, 10178 Berlin, Germany\n",
    "* Galeria Kaufhof Berlin, Dircksenstr. 2, 10178 Berlin, Germany\n",
    "\n",
    "are within of 200 metres or less of each other. As a result, we dropped the later from our final dataset. \n",
    "\n",
    "As a note, the code can certainly be optimized. Furthermore, once you have a cleaned dataframe, it's not necessary to check for every possible combinations anymore. So memory usage can be reduced and computation time can be shorten."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
