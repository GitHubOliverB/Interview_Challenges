{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going From Loops to Vectorization\n",
    "\n",
    "__Problem:__\n",
    "\n",
    "You are given a loop in the form of\n",
    "\n",
    "``\n",
    "for i in range(N):\n",
    "    maybe some inner loops:\n",
    "        do logic\n",
    "        ...\n",
    "    do more logic\n",
    "    return result\n",
    "``\n",
    "\n",
    "The logic part is almost always a mathematical operation. Let's take the example of a linear regression with N features:\n",
    "\n",
    "$$ y_i = \\beta_0 + \\beta_1\\cdot x_{i,1} + ... \\beta_N\\cdot x_{i,N}$$\n",
    "\n",
    "We can compute a specific $y_i$ by pluggin in $x_{i,1}$ to $x_{i,N}$. For a given $i$, this can be achieved via a loop like:\n",
    "\n",
    "``\n",
    "beta = [beta_1, ... , beta_N]\n",
    "x = [x_1, ... , x_N]\n",
    "for k in range(N):\n",
    "    y += beta[k]*x[k]\n",
    "y += beta_0\n",
    "``\n",
    "\n",
    "Also we can take the last addition of beta_0 and take it into the first loop by inserting a $1$ in x and $\\beta_0$ in beta.\n",
    "\n",
    "``\n",
    "beta = [beta_0, beta_1, ... , beta_N]\n",
    "x = [1, x_1, ... , x_N]\n",
    "for k in range(0,N+1):\n",
    "    y += beta[k]*x[k]\n",
    "``\n",
    "\n",
    "If we want to compute all $y_i$, say a total of P, and store our result in a variable $y$, we can insert an other loop:\n",
    "\n",
    "``\n",
    "beta = [beta_0, beta_1, ... , beta_N]\n",
    "X = [[1, x_11, ... , x_1N], ..., [1, x_P1, ... , x_PN]]\n",
    "for i in range(0,P):\n",
    "    for k in range(0,N+1):\n",
    "        y[0][i] += beta[k]*X[k][i]\n",
    "``\n",
    "\n",
    "__Task:__\n",
    "\n",
    "Rewrite the linear regression formula in terms of vectors and matrices and make use of the matrix multiplication in Numpy. Compare the results and the computing time for both methods.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take $Y$ as a (1,P)-dimensional matrix, $\\beta$ as a (1,N)-dimensional matrix and X as a (N,P)-dimensional matrix (forget about $\\beta_0$). Then we can write:\n",
    "\n",
    "$$Y = \\beta \\cdot X$$\n",
    "\n",
    "Using Numpy, this is computed via:\n",
    "\n",
    "``\n",
    "Y = np.dot(beta,X)\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "P = 10000\n",
    "\n",
    "beta = np.random.rand(1,N)# Vectorized code\n",
    "X = np.random.rand(N,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for vectorized code is : 4.989 ms\n"
     ]
    }
   ],
   "source": [
    "# Take Time\n",
    "t_1=time.time()\n",
    "\n",
    "# Using matrix multiplication\n",
    "Y = np.dot(beta,X)\n",
    "print(\"Time taken for vectorized code is : {:.3f} ms\".format((time.time()-t_1)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for non vectorized code is : 11442.472 ms\n"
     ]
    }
   ],
   "source": [
    "# Take Time\n",
    "t_2 = time.time()\n",
    "\n",
    "# Using loop\n",
    "Y_Loop = np.zeros((1,P))\n",
    "for i in range(X.shape[1]):\n",
    "    for k in range(X.shape[0]):\n",
    "        Y_Loop[0][i] += beta[0,k]*X[k,i]\n",
    "        \n",
    "print(\"Time taken for non vectorized code is : {:.3f} ms\".format((time.time()-t_2)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first 10 P's:\n",
      "Matrix Multiplication: [255.90640043 261.75314558 259.15497789 258.46010875 259.50359699\n",
      " 266.75118414 255.7712528  264.85873545 245.04342784 254.4761386 ]\n",
      "Loop: [255.90640043 261.75314558 259.15497789 258.46010875 259.50359699\n",
      " 266.75118414 255.7712528  264.85873545 245.04342784 254.4761386 ]\n",
      "\n",
      "For the last 10 P's:\n",
      "Matrix Multiplication: [260.42655898 256.77749943 246.51479199 253.10741165 253.67408939\n",
      " 258.90529259 258.26646146 256.29505292 263.58947663 257.69502227]\n",
      "Loop: [260.42655898 256.77749943 246.51479199 253.10741165 253.67408939\n",
      " 258.90529259 258.26646146 256.29505292 263.58947663 257.69502227]\n"
     ]
    }
   ],
   "source": [
    "print(\"For the first 10 P's:\")\n",
    "print(\"Matrix Multiplication: {}\".format(Y[0,:10]))\n",
    "print(\"Loop: {}\".format(Y_Loop[0,:10]))\n",
    "print()\n",
    "print(\"For the last 10 P's:\")\n",
    "print(\"Matrix Multiplication: {}\".format(Y[0,-10:]))\n",
    "print(\"Loop: {}\".format(Y_Loop[0,-10:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all and most importantly, we end up with the exact same result for both methods. \n",
    "The interesting thing to note however is that using the __matrix multiplication methode, we reduced the computing time by at least 3 orders of magnitude__. For this particular example, I found that the matrix multiplication method was faster by a factor of roughly 2,300.\n",
    "\n",
    "Hence it is more than recommended to __avoid loops and use vectorization__ if possible!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
